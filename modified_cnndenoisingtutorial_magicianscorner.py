# -*- coding: utf-8 -*-
"""Modified_CNNDenoisingTutorial_MagiciansCorner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N8V56eHEx3uIWIahBvRGAorszAziyAs7

https://github.com/bnel1201/Ped-ETK

https://github.com/DIDSR/LCD_CT

Standard LCD Dataset: https://zenodo.org/record/7996580

Peds LCD Dataset: https://sandbox.zenodo.org/record/1213653

https://1drv.ms/w/s!AgJOdaganUhLjuldvIYTe20hA3Eyzw?e=6h7ZGM

# Convolutional Neural Network Denoising: Computed Tomography
---
*Authors: Nathan R. Huber and Andrew D. Missert*

This tutorial demonstrates the application of deep convolutional neural networks (CNNs) for reducing noise in computed tomography (CT) images. By leveraging the prior information contained in many examples of low-noise and high-noise images, CNN denoising can reduce noise in CT images while maintaining high levels of anatomic detail.

This tutorial presents a simple overview of the training procedure for illustrative purposes, and is not intended to produce an optimal result. No Python coding experience or machine learning knowledge is necessary or assumed.
"""

# !pip install pyyaml h5py  # Required to save models in HDF5 format

# import yaml
# import h5py
import urllib

#Cell 1

# %tensorflow_version 1.x
import tensorflow as tf

from tensorflow import keras
from scipy import ndimage, misc
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.style as style
import time
import os

"""## Loading Data

In order to train the CNN, we need many examples of low-noise and high-noise images. We must also be careful to evaluate the denoising performance on different images than those used for training. This can be done by partitioning the data into **training** examples, which are used to optimize the CNN parameters, **validation** examples, which are used to monitor the optimization process, and **testing** examples, which are used to check performance.

The data used in this tutorial is made available through the AAPM and Mayo Clinic Low Dose CT Grand Challenge (Medical Physics 44(10), 2017). Each training example consists of a pair of images: the input, which is a simulated 25% dose CT image, and the target, which is the corresponding routine dose CT image.

![alt text](https://drive.google.com/uc?id=1dBzBOk1ZejqZ8as9cioyXB--8X0z0SST)


"""

#Cell 2

import zipfile
if not os.path.exists('data'): os.mkdir('data')
if not os.path.exists('data/Denoising_Data'):
  os.mkdir('data')
  urllib.request.urlretrieve('https://docs.google.com/uc?export=download&id=1-ZqL_1cqWeG6LsRAB0TwiddW8TgQ-q70', 'data/Denoising_Data.zip')
  with zipfile.ZipFile('data/Denoising_Data.zip', 'r') as zip_ref:
     zip_ref.extractall('data')

#Cell 3
# load training data, used to update CNN weights
# 2000 30x30 image patches from 8 patients
train_input = np.load('data/Denoising_Data/train_input.npy')
train_target = np.load('data/Denoising_Data/train_target.npy')
# load validation data, used to monitor for overfitting
# 1000 30x30 image patches from 1 patient
val_input = np.load('data/Denoising_Data/val_input.npy')
val_target = np.load('data/Denoising_Data/val_target.npy')

# load testing data, used for evaluating performance
# 5 512x512 images from 1 patient
test_input = np.load('data/Denoising_Data/test_input.npy')
test_target = np.load('data/Denoising_Data/test_target.npy')

# Load examples images from state-of-the-art CNN denoising for CT images
test_example = np.load('data/Denoising_Data/test_input_denoised.npy')



print('Data loading completed.')

train_input.shape, train_target.shape

#Cell 4

# This is a helper function that plots images using typical CT windows
def ctshow(img, window='soft_tissue'):

  # Define some specific window settings here
  if window == 'soft_tissue':
    ww = 400
    wl = 40
  elif window == 'bone':
    ww = 2500
    wl = 480
  elif window == 'lung':
    ww = 1500
    wl = -600
  else:
    ww = 6.0 * img.std()
    wl = img.mean()

  # Plot image on clean axes with specified window level
  vmin = wl - ww // 2
  vmax = wl + ww // 2
  plt.imshow(img, cmap='gray', vmin=vmin, vmax=vmax)
  plt.xticks([])
  plt.yticks([])

  return

#Cell 5

# Get a few examples of training patches
image_examples = [3, 16, 36]
window = 'soft_tissue'

for row in range(2):

  plt.figure(figsize=(12, 12))
  nexample = image_examples[row]

  # Simulated low-dose example
  plt.subplot(3, 3, 1+row*3)
  plt.title('Low Dose Patch', fontsize=16)
  ctshow(train_input[nexample, :, :, 0], window=window)

  # Simulated routine-dose example
  plt.subplot(3, 3, 2+row*3)
  plt.title('Routine Dose Patch', fontsize=16)
  ctshow(train_target[nexample, :, :, 0], window=window)
  plt.subplot(3, 3, 3+row*3)

  # Difference between low-dose and routine-dose to visualize CT noise
  plt.title('Difference', fontsize=16)
  ctshow(train_target[nexample, :, :, 0] - train_input[nexample, :, :, 0],
           window=window)

"""## Building Keras model:

CNNs are simply mathematical functions that consist of repeated convolution operations. Each convolutional layer convolves multiple filters (kernels) over the input images. The values used for each filter are free parameters that are adjusted during the training procedure. A simple non-linear activation function is also applied between the convolutional layers.

Provided below is a basic model for CNN denoising containing convolutional layers and ReLU activation layers. Each layer operates on the output of the previous layer.

![](https://drive.google.com/uc?id=1wVJJ1olpxpXSFo32bbFjUZhjHW4uUiiF)


"""

#Cell 6

# This specifies the number of convolutonal layers in the model
n_layers = 6

# This specifies the number of convolutional filters in each convolutional layer
filters = 64

# This specifies the size of the filter in each convolutional layer
kernel_size = (3, 3)

# This specifies the number of pixels the filter translates at each step
strides = (1, 1)

# This specifies the non-linear function applied after each convolutionaly layer
activation = 'relu'


# This function builds the model according to the parameters set above
def build_model():

    # The input tensor image can have arbitrary spatial extent, but just
    # one channel for the grayscale CT images
    xin = keras.layers.Input(shape=(None, None, 1), name='input_CT_images')

    # We define a preprocessing layer to rescale the CT image pixel values
    shift_mean = train_input.mean()
    rescale = train_input.std()
    x = keras.layers.Lambda(
        lambda x: (x - shift_mean) / rescale,
        name='normalization')(xin)

    # This loop adds each convolutional layer
    for i in range(n_layers - 1):
        x = keras.layers.Conv2D(
          filters=filters,
          kernel_size=kernel_size,
          strides=strides,
          padding='same')(x)
        x = keras.layers.Activation(activation)(x)

    # Final layer has just one feature map corresponding to the output image
    x = keras.layers.Conv2D(
        filters=1,
        kernel_size=kernel_size,
        strides=strides,
        padding='same')(x)

    # Here we rescale the output to typical CT number range
    xout = keras.layers.Lambda(
        lambda x: (x * rescale) + shift_mean,
        name='output_CT_images')(x)

    # We define the model by specifying the inputand output tensors
    model = keras.Model(inputs=xin, outputs=xout, name="CT_denoiser")
    return model


denoising_model = build_model()
denoising_model.summary()

"""## Optimization: Training the network

Take a moment to appreciate the number of trainable parameters listed in the model summary above. These parameters start off randomly initialized and must be optimized to perform a denoising task.

It is worth noting that this denoising task is ill-posed. We should not expect to reconstruct the signal exactly, but we can make a prediction that agrees with the observed noisy data and prior knowledge. During optimization, we aim to have the CNN encode meaningful prior knowledge from many training examples into the predictions.

For this part of the tutorial, the CNN parameters will be optimized with one goal in mind: to minimize the mean-squared-error (MSE) difference between the CNN output images and the low-noise target images.

We can train the model provided the datasets we previously loaded. When running on Google Colab, you will want to utilize a GPU for this optimization procedure. Click **Runtime** above, then **Change Runtime Type** in the drop down menu, finally select **GPU** under hardware accelerator. It should take the GPU under three minutes to train the model with default parameters.
"""

#Cell 7

# This sets the number of iterations through the training data
epochs = 15

# This sets the number of images patches used to calcualte a single
# parameter update.
batch_size = 32

# This is a scaling factor that affects the magnitude of each optimization step
learning_rate = 0.0001

# The optimizer manages how the parameters are updated from each gradient
# calculation
optimizer = tf.keras.optimizers.legacy.Adam(lr=learning_rate)


# As the training progresses, we'll monitor network output and performance
# metrics
progress_example = 2
buffer = 128
progress_ims = []

def train(loss_function, model):

    model.compile(optimizer=optimizer, loss=loss_function)

    # As the training progresses, we'll monitor network output and performance
    # metrics. Some related variables are initialized here
    example_input = test_input[[3], ...]
    edge_buffer = 128
    progress_ims = []
    progress_val = []

    for epoch in range(epochs):

      # Evaluate model on reserved data
      val_loss = model.evaluate(val_input, val_target)
      example_output = model.predict(example_input)
      example_img = example_output[0, edge_buffer:-edge_buffer,
                                edge_buffer:-edge_buffer, 0]
      progress_ims.append(example_img)
      progress_val.append(val_loss)

      # Update model weights using training data
      istart = 0
      while istart < (len(train_input) - batch_size):
          x = train_input[istart:istart + batch_size]
          y = train_target[istart:istart + batch_size]
          model.train_on_batch(x=x, y=y)
          istart += batch_size

    progress_ims = np.stack(progress_ims, axis=0)

    print('Training phase complete.')
    return model, progress_ims, progress_val


# Now run the training fuction to obtain the trained model and performance at
# intermediate steps
denoising_model, progress_ims, progress_val = train(loss_function='mse', model=denoising_model)

import tensorflow as tf
print(tf.__version__)

import zipfile

import shutil

tf.keras.models.save_model(denoising_model, 'models/simple_cnn_denoiser')

#Cell 8

# Here we show some example images from different epochs in the training
# procedure.

plt.figure(figsize=(12, 12))

plt.subplot(2, 2, 1)
plt.title('Before Optimization', fontsize=16)
ctshow(progress_ims[0, :, :], window='variable')

plt.subplot(2, 2, 2)
plt.title('Epoch %d/%d' %(1, epochs), fontsize=16)
ctshow(progress_ims[1, :, :], window='soft_tissue')

plt.subplot(2, 2, 3)
plt.title('Epoch %d/%d' %(5, epochs), fontsize=16)
ctshow(progress_ims[5, :, :], window='soft_tissue')

plt.subplot(2, 2, 4)
plt.title('Final Epoch', fontsize=16)
ctshow(progress_ims[-1, :, :], window='soft_tissue')

"""### Inference: Testing the network

Now that the network is fully trained, we can apply to our CNN in inference mode to the reserved testing data to check the performance. Since all CNN parameters are fixed at this point, the processing time for this phase is typically very fast.

Here we include a comparison with a Gaussian smoothing filter. Notice that the CNN is able to better maintain feature resolution relative to the Gaussian filter. The improvment is most notable at high contrast boundaries.




"""

test_input.shape

# CNNout.shape

#Cell 9

# Display an example input image, the denoised image, and the difference
nexample = 1
CNNout = denoising_model.predict(test_input, batch_size=1)

plt.figure(figsize=(16, 8))

plt.subplot(1, 3, 1)
plt.title('Low Dose Input', fontsize=16)
ctshow(test_input[nexample, :, :, 0])

plt.subplot(1, 3, 2)
plt.title('Estimated Noise Map', fontsize=16)
ctshow(test_input[nexample, :, :, 0] - CNNout[nexample, :, :, 0])

plt.subplot(1, 3, 3)
plt.title('CNN Denoised Image', fontsize=16)
ctshow(CNNout[nexample, :, :, 0])

# Same as above, but with a different field of view
plt.figure(figsize=(16, 8))

plt.subplot(1, 2, 1)
plt.title('Gaussian Filter', fontsize=16)
gaussfilt = ndimage.gaussian_filter(test_input[3, :, :, 0], sigma=1.4)
ctshow(gaussfilt[110:-110, 50:-50])

plt.subplot(1, 2, 2)
plt.title('CNN Denoised, MSE', fontsize=16)
ctshow(CNNout[3, 110:-110, 50:-50, 0])

"""## Feature loss using VGG16:

The choice of loss function has a substantial impact on the denoising result. Our initial MSE loss function is a pixel-per-pixel comparison between the denoised image and the routine-dose reference. In order to develop a metric that better corresponds to image quality, this loss function may be supplemented by metrics that perform non-local comparisons of image features. One such approch is feature loss, which computes the MSE between feature maps of a pre-trained image classification network. Here we demonstrate this loss using the VGG16 network trained on ImageNet data.


![alt text](https://drive.google.com/uc?id=1tYPdT-o4VFKK2q9aJ0F7tNZhBc3f5SOx)

"""

#Cell 10

# Load the pre-trained VGG model from Keras
modelVGG = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, pooling=None)
modelVGG.summary()

#Cell 11

# Here we specify which layers we will use to use to define the feature loss
# Then we build a model that outputs the feature maps of these layers
feature_loss_layers = [
    'block3_conv3'
]

def get_VGG_features(feature_layers):

  # VGG expects normalized inputs, so we need to do some preprocessing to the CT
  # images first
  stack_layer = keras.layers.Lambda(lambda x: tf.tile(x, [1, 1, 1, 3]), name='CT_stack')
  preproc_layer = keras.layers.Lambda(lambda x: (x + 1024.0)/1500., name='CT_preprocess')
  clip_layer = keras.layers.Lambda(lambda x: tf.clip_by_value(x, 0.0, 1.0), name='CT_clip')

  # Get VGG input and add preprocesing layers
  inputs = keras.layers.Input(shape=(None, None, 1))
  x = stack_layer(inputs)
  x = preproc_layer(x)
  x = clip_layer(x)

  # Re-connect subsequent layers, and add to output if layer was specified
  # for feature loss
  outputs = []
  for layer in modelVGG.layers[1:]:
    x = layer(x)
    if layer.name in feature_loss_layers:
      print('Adding layer {} to output'.format(layer.name))
      outputs.append(x)

  vgg_feature_model = keras.Model(inputs, outputs)
  return vgg_feature_model

feature_model = get_VGG_features(feature_loss_layers)
feature_model.trainable = False
feature_model.summary()

#Cell 13

# Run an example CT image through VGG model and plot a random selection of
# feature maps
y = feature_model.predict(test_input[[1]])
plt.figure(figsize=(16, 9))
nexamples = 7

for i in range(nexamples):
  plt.subplot(1, nexamples, i+1)
  ifeature = np.random.choice(256, replace=False)
  plt.axis('off')
  plt.title('Feature {}/256'.format(ifeature))
  plt.imshow(y[0, :, :, ifeature])

#Cell 14

# Now we use the feature model to build a loss function that compares the VGG
# features between the CNN-denoised output (y_pred) and the routine-dose
# reference (y_true).
def build_feature_loss(feature_extractor, mse_scale=0.01):

  def vgg_feature_loss(y_true, y_pred):

    # extract features and compute feature loss
    y_true_features = feature_extractor(y_true)
    y_pred_features = feature_extractor(y_pred)

    if type(y_true_features) == list:
      feat_loss = 0.0
      for itrue, ipred in zip(y_true_features, y_pred_features):
        feat_loss += tf.reduce_mean(tf.square(itrue - ipred))
    else:
      feat_loss = tf.reduce_mean(tf.square(y_true_features - y_pred_features))

    # also compute pixel-wise MSE loss
    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))

    total_loss = feat_loss + (mse_scale * mse_loss)

    return total_loss

  return vgg_feature_loss

feature_loss = build_feature_loss(feature_model)

#Cell 15

# Build a new denoising model (same architcture as before!),
# and optimize the weights using feature loss
model_vggloss = build_model()
model_vggloss.summary()

#Cell 16

model_vggloss, progress_ims, progress_val = train(loss_function=feature_loss, model=model_vggloss)

model_vggloss.save('models/model_vggloss')

"""### Inference: Comparing the loss functions

Now that the model has been optimized with two different loss functions, we want to compare their ability to reduce noise while maintaining resolution of anatomic features. In order to assess the accuracy of CNN denoising we often visually compare the CNN denoised low dose images to the routine dose image. To assess the ability to maintain resolution we often use line profiles.

The MSE loss function had more extensive noise reduction. The feature loss function was able to better maintain CT texture in the image. Both loss functions had similar ability to retain resolution at a high contrast interface. Altering the loss function has a large impact on CNN denoising performance.

The Gaussian smoothing filter is again provided for comparison. Observe how the CNN denoised image with feature loss was able to fine structures much better than the Gaussain smoothing filter.
"""

#Cell 17

# Run models on reserved testing data
CNNout_mseloss = denoising_model.predict(test_input)
CNNout_vggloss = model_vggloss.predict(test_input)

# Plot for visual inspection of image quality
buffer = 32
plt.figure(figsize=(16, 8))
plt.subplot(1, 4, 1)
plt.title('Low Dose Input', fontsize=16)
ctshow(test_input[1, buffer:-buffer, buffer:-buffer, 0])

plt.subplot(1, 4, 2)
plt.title('CNN Denoised \n MSE Loss', fontsize=16)
ctshow(CNNout_mseloss[1, buffer:-buffer, buffer:-buffer, 0])

plt.subplot(1, 4, 3)
plt.title('CNN Denoised \n MSE + Feature Loss', fontsize=16)
ctshow(CNNout_vggloss[1, buffer:-buffer, buffer:-buffer, 0])

plt.subplot(1, 4, 4)
plt.title('Original Routine Dose', fontsize=16)
ctshow(test_target[1, buffer:-buffer, buffer:-buffer, 0])

plt.figure(figsize=(16, 8))

plt.subplot(1, 2, 1)
plt.title('Gaussian Filter', fontsize=16)
gaussfilt = ndimage.gaussian_filter(test_input[3, :, :, 0], sigma=1.4)
ctshow(gaussfilt[110:-110, 50:-50])

plt.subplot(1, 2, 2)
plt.title('CNN Denoised, MSE + Feature Loss', fontsize=16)
ctshow(CNNout_vggloss[3, 110:-110, 50:-50, 0])

#High contrast resolution evaluation:
CNNout_mseloss = denoising_model.predict(test_input)
CNNout_vggloss = model_vggloss.predict(test_input)

# Standard deviation noise in approximately uniform region (aorta)
std_in = test_input[0, 222:237, 203:218, 0].std()
std_cnn_mse = CNNout_mseloss[0, 222:237, 203:218, 0].std()
std_cnn_vgg = CNNout_vggloss[0, 222:237, 203:218, 0].std()
style.use('seaborn-white')

plt.figure(figsize=(15, 15))
plt.subplot(1, 3, 1)
plt.title('Low Dose Input\n Noise level at aorta (SD) = %.4g HU' % std_in, fontsize=12)
ctshow(test_input[0, 207:307, 151:231, 0], window='bone')
plt.plot([7, 57], [70, 70], 'mediumblue', lw=3)
plt.axis('off')
plt.subplot(1, 3, 2)
plt.title('CNN Denoised: MSE Loss\n Noise level at aorta (SD) = %.4g HU' % std_cnn_mse, fontsize=12)
ctshow(CNNout_mseloss[0, 207:307, 151:231, 0], window='bone')
plt.plot([7, 57], [70, 70], 'crimson', lw=3)
plt.axis('off')
plt.subplot(1, 3, 3)
plt.title('CNN Denoised: Feature Loss\n Noise level at aorta (SD) = %.4g HU' % std_cnn_vgg, fontsize=12)
ctshow(CNNout_vggloss[0, 207:307, 151:231, 0], window='bone')
plt.plot([7, 57], [70, 70], 'green', lw=3)
plt.axis('off')
plt.show()

# Line profile comparison
style.use('seaborn-whitegrid')
plt.figure(figsize=(14, 6))
plt.plot(test_input[0, 276, 158:209, 0], label="Low Dose Input",color='mediumblue')
plt.plot(CNNout_mseloss[0, 276, 158:209, 0], label="CNN Denoised: MSE Loss",color='crimson')
plt.plot(CNNout_vggloss[0, 276, 158:209, 0], label="CNN Denoised: Feature Loss",color='green')
plt.xlabel('Profile (pixels)')
plt.ylabel('Signal (HU)')
plt.legend(loc='upper center', fontsize = 12)
plt.show()

"""## Insert LCD and Size-Based Analyses Here...
Start by downloading the images and running the standard LCD code

## Discussion

The exercises in this tutorial are for illustrative purposes only and are not intended to produce state-of-the-art results. As such, the denoised images above contain numerous artifacts which may interfere with the diagnostic quality. However, with further refinement of the technique, CNNs can become powerful tools for reducing noise while maintaining anatomic details. As an example, in the cell below we compare the results from this demo to those from our ongoing research in this area.

CNN-based noise reduction leverages prior information from the training data to distinguish between noise and anatomic background. Ideally, this approach can be used to reduce the impact of noise on diagnostic quality. For CT imaging, this can free up some space in the "noise budget" to use thinner slices, sharper kernels, or even lower dose for clinical exams. However, no noise reduction algorithm is perfect and at some noise level, image features will be irreversibly lost. Extensive further study is required to assess the potential limitations of this emerging technology for improving patient care.
"""

#Cell 18

# Load full quarter dose test image and display result
nexample = 3

window_width = 400
window_level = 40
vmin = window_level - window_width // 2
vmax = window_level + window_width // 2

plt.figure(figsize=(18, 8))
plt.subplot(1, 4, 1)
plt.title('Low Dose Input', fontsize=16)
ctshow(test_input[nexample, :, :, 0])

plt.subplot(1, 4, 2)
plt.title('Demo CNN Output', fontsize=16)
ctshow(CNNout_vggloss[nexample, :, :, 0])

# These are some examples from an individually-tuned CNN.
# These results were presented in at the 2019 RSNA Annual Meeting
# (Missert, et al. "Patient-Specific Noise Reduction Using a Deep Convolutional Neural Network" (SSE24-02))
plt.subplot(1, 4, 3)
plt.title("Individualized CNN Denoising", fontsize=16)
ctshow(test_example[nexample, :, :, 0])

plt.subplot(1, 4, 4)
plt.title('Original Routine Dose', fontsize=16)
ctshow(test_target[nexample, :, :, 0])

# Same as above, but zoomed in to see more details
plt.figure(figsize=(18, 8))
plt.subplot(1, 4, 1)
plt.title('Low Dose Input', fontsize=16)
ctshow(test_input[nexample, 150:350, 150:350, 0])

plt.subplot(1, 4, 2)
plt.title('Demo CNN Output', fontsize=16)
ctshow(CNNout_vggloss[nexample, 150:350, 150:350, 0])

plt.subplot(1, 4, 3)
plt.title('Individualized CNN Denoising', fontsize=16)
ctshow(test_example[nexample, 150:350, 150:350, 0])

plt.subplot(1, 4, 4)
plt.title('Original Routine Dose', fontsize=16)
ctshow(test_target[nexample, 150:350, 150:350, 0])

plt.show()

"""We acknowledge Dr. Cynthia McCollough, the Mayo Clinic, the American Association of Physicists in Medicine, and grants EB017095 and EB017185 from the National Institute of Biomedical Imaging and Bioengineering for distributing the data used within this publication."""
